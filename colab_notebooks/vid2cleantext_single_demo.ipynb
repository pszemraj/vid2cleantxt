{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "vid2cleantext_single_GPU.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true,
   "machine_shape": "hm",
   "authorship_tag": "ABX9TyPTHRBMfCTABs3JcLRyQ3BJ",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "dfa4cec8e4ae4d6b8ba181b8271f5f12": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_36301db4e912457fb2ad3b28f7a63179",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_02f7bcad7a034aedaff12487945c609b",
       "IPY_MODEL_1a34c092d8514655a5a7d95c8881f18d",
       "IPY_MODEL_9aa06210e96b48a5bf288bf357f58aa9"
      ]
     }
    },
    "36301db4e912457fb2ad3b28f7a63179": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "02f7bcad7a034aedaff12487945c609b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_d627fd9297644f128554e0300982de7a",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "Downloading: 100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_6958d235a28241eea3865f4b6fa82104"
     }
    },
    "1a34c092d8514655a5a7d95c8881f18d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_443bd4a8bf184e2d992d46444a5159f1",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 291,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 291,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_8d6139109f2b41fe9068ea9645409d8b"
     }
    },
    "9aa06210e96b48a5bf288bf357f58aa9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_0ed860e92b0b4befb286ca705d831e82",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 291/291 [00:00&lt;00:00, 6.72kB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_c31cb89839fd4b428da58d3e122d48d1"
     }
    },
    "d627fd9297644f128554e0300982de7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "6958d235a28241eea3865f4b6fa82104": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "443bd4a8bf184e2d992d46444a5159f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "8d6139109f2b41fe9068ea9645409d8b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "0ed860e92b0b4befb286ca705d831e82": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "c31cb89839fd4b428da58d3e122d48d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "63ea06b651d54b3cbca55458af1a0e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_948040264bee418a96aacf5ae7b7cbbc",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_3f4f0c5b80814d52b7f33b8833e7766c",
       "IPY_MODEL_5682b194994f4dda977c448a11b1ad17",
       "IPY_MODEL_04986152213344929bae81cdd88da197"
      ]
     }
    },
    "948040264bee418a96aacf5ae7b7cbbc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "3f4f0c5b80814d52b7f33b8833e7766c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_cbd34e24ad1445389efc51fc54f6e349",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "Downloading: 100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_0461719f0ee449c8a02efa71e1e7d61f"
     }
    },
    "5682b194994f4dda977c448a11b1ad17": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_dd2c514c869b4b67a6c9e43bd2f377af",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 162,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 162,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_e9ab096b4a634f3ebd8512d775285257"
     }
    },
    "04986152213344929bae81cdd88da197": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_2cc720f566c14efc8c5f059d0e368e36",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 162/162 [00:00&lt;00:00, 4.74kB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_14fc86d70a3d4bb09ffa1d3acc4ad3e6"
     }
    },
    "cbd34e24ad1445389efc51fc54f6e349": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "0461719f0ee449c8a02efa71e1e7d61f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "dd2c514c869b4b67a6c9e43bd2f377af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "e9ab096b4a634f3ebd8512d775285257": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "2cc720f566c14efc8c5f059d0e368e36": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "14fc86d70a3d4bb09ffa1d3acc4ad3e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "0656f1d7f415416db150b597e92fa339": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_e46d1e6b584a4e3292a835239243a8a4",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_a0041df82ede426aac32e932efa32d26",
       "IPY_MODEL_b214c360d2ac438b9304f99f4c8be92e",
       "IPY_MODEL_70bf93b0c19245ba944107328f9c42b8"
      ]
     }
    },
    "e46d1e6b584a4e3292a835239243a8a4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "a0041df82ede426aac32e932efa32d26": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_8e9675a3401043869808862204ad6122",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "Downloading: 100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_69e47adca28b43fe816b11ea73311ae7"
     }
    },
    "b214c360d2ac438b9304f99f4c8be92e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_926a0035f13b493088f888f7e78eb8f4",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 85,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 85,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_677d881f99764dee92e71f4100f649c4"
     }
    },
    "70bf93b0c19245ba944107328f9c42b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_87861e3f433a4e4eabf84c3c145a3a32",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 85.0/85.0 [00:00&lt;00:00, 2.64kB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_1741e4927f674a89bbe7602fcc15668e"
     }
    },
    "8e9675a3401043869808862204ad6122": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "69e47adca28b43fe816b11ea73311ae7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "926a0035f13b493088f888f7e78eb8f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "677d881f99764dee92e71f4100f649c4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "87861e3f433a4e4eabf84c3c145a3a32": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "1741e4927f674a89bbe7602fcc15668e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "76122e8529ab4cdb9d3bcb6e04eeceab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_f0ae2fd16d3e4db78d79f199717c2443",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_5f87457338ef4e3a96d0319342565707",
       "IPY_MODEL_a431840ff75c4e1db36858079e0b5e5f",
       "IPY_MODEL_cbc35df79bf64370ae00fb1a774dc834"
      ]
     }
    },
    "f0ae2fd16d3e4db78d79f199717c2443": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "5f87457338ef4e3a96d0319342565707": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_ea521fcea80a46d685a130f45da0b11b",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "Downloading: 100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_a2e3ae60c66149a490108b7fa5901efe"
     }
    },
    "a431840ff75c4e1db36858079e0b5e5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_f69ca3251c7e4b38ad2153b6fe8a7ef1",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 1606,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 1606,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_c5734af7f84c43a2b7e2ba8ee250570e"
     }
    },
    "cbc35df79bf64370ae00fb1a774dc834": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_81203315409348c6955a025774e10151",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 1.61k/1.61k [00:00&lt;00:00, 50.8kB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_2243b131c8014415b466619a116439a2"
     }
    },
    "ea521fcea80a46d685a130f45da0b11b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "a2e3ae60c66149a490108b7fa5901efe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "f69ca3251c7e4b38ad2153b6fe8a7ef1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "c5734af7f84c43a2b7e2ba8ee250570e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "81203315409348c6955a025774e10151": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "2243b131c8014415b466619a116439a2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "0263e1f539cc4aa6b9ad9ac354454d47": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_d4613be8952a4e24802460eba2311798",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_92ecae1b4161419da4c32b63736b7892",
       "IPY_MODEL_9e20c764f02a48908afafc6e962f2277",
       "IPY_MODEL_8c33bbda09614b5f813e2381060b1e0d"
      ]
     }
    },
    "d4613be8952a4e24802460eba2311798": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "92ecae1b4161419da4c32b63736b7892": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_7db51c8129934ebc92b7489efe009f4d",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "Downloading: 100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_c8574c98f6ff498d8b3c63d8fd8e78a6"
     }
    },
    "9e20c764f02a48908afafc6e962f2277": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_3c3af295d4f24f6f8c301b7fe63213d6",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 1262055246,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 1262055246,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_f407ca06b5e64bf79c09e4a00776db9c"
     }
    },
    "8c33bbda09614b5f813e2381060b1e0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_5bac7f603d824c9983997f42e602772e",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 1.26G/1.26G [00:33&lt;00:00, 39.6MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_0d838106c8a7478bb13b3e3e652c322b"
     }
    },
    "7db51c8129934ebc92b7489efe009f4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "c8574c98f6ff498d8b3c63d8fd8e78a6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "3c3af295d4f24f6f8c301b7fe63213d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "f407ca06b5e64bf79c09e4a00776db9c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "5bac7f603d824c9983997f42e602772e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "0d838106c8a7478bb13b3e3e652c322b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "caad4d5707b94fbbb1840b7c8bf60580": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_469616e95d2648e7ae7fc406dcc93c09",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_0a21b37adbd947ceb3304819b969d9e0",
       "IPY_MODEL_6f39d81448d848d497630193bfc0612d",
       "IPY_MODEL_674e9d27d8b7447e8f72c5ff86d40900"
      ]
     }
    },
    "469616e95d2648e7ae7fc406dcc93c09": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "0a21b37adbd947ceb3304819b969d9e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_4f86feb219df4692a4361e07eb072147",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "Converting Video to Audio Chunks: 100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_165667e75fe841fca15e1e783cfee911"
     }
    },
    "6f39d81448d848d497630193bfc0612d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_88f548f1ec7d48aba62500e9b0b8431f",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 9,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 9,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_54c0ddb5c31a4cf1844ed03554d313c2"
     }
    },
    "674e9d27d8b7447e8f72c5ff86d40900": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_b922fbd5c9e94bf3b659b1a874056fb0",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 9/9 [00:04&lt;00:00,  2.15it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_3b789227150246c9a584ec1b74560b76"
     }
    },
    "4f86feb219df4692a4361e07eb072147": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "165667e75fe841fca15e1e783cfee911": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "88f548f1ec7d48aba62500e9b0b8431f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "54c0ddb5c31a4cf1844ed03554d313c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "b922fbd5c9e94bf3b659b1a874056fb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "3b789227150246c9a584ec1b74560b76": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "bd862f1ef58e4a59a4238f05a841c38c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_20d9b9d3d0c6401a90c100bec9d6652c",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_e1116c3d8e8c4e6fa531b6cbbd29f54b",
       "IPY_MODEL_7bda4e420bb4484292ddec3d6db3fb5b",
       "IPY_MODEL_9bce9c338c5c497092901fbef6c14e81"
      ]
     }
    },
    "20d9b9d3d0c6401a90c100bec9d6652c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "e1116c3d8e8c4e6fa531b6cbbd29f54b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_72702c2e3b094fe8830a626454e69f3e",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "wav2vec2 model for JFK_rice_moon_speech.mp4: 100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_1b70355b3f2f4b19acaa11f23a35e1f7"
     }
    },
    "7bda4e420bb4484292ddec3d6db3fb5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_715724e299b14424b977973b847bb095",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 9,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 9,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_411998ca28dd4be7a174c6dc0f12a464"
     }
    },
    "9bce9c338c5c497092901fbef6c14e81": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_ddcf632379db417e959ff74fc76ac868",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 9/9 [00:19&lt;00:00,  1.32s/it]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_68332b0b56cd4c6191a31d7263f60cf9"
     }
    },
    "72702c2e3b094fe8830a626454e69f3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "1b70355b3f2f4b19acaa11f23a35e1f7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "715724e299b14424b977973b847bb095": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "411998ca28dd4be7a174c6dc0f12a464": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "ddcf632379db417e959ff74fc76ac868": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "68332b0b56cd4c6191a31d7263f60cf9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pszemraj/vid2cleantxt/blob/master/colab_notebooks/vid2cleantext_single_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oiurzXGg8DyC"
   },
   "source": [
    "# vid2cleantxt - single file version on Colab\n",
    "Peter Szemraj\n",
    "\n",
    "[Link to full GitHub Repo](https://github.com/pszemraj/vid2cleantxt)\n",
    "\n",
    "## Purpose\n",
    "\n",
    "A quick demo of vid2cleantxt.\n",
    "\n",
    "\n",
    "* Downloads a video to transcribe, converts the video file to audio chunks, runs those chunks through facebook's wav2vec2 pretrained speech transcription model. \n",
    "* After saving original transcription, it also creates a version that is spell-corrected, and a third version with sentence boundary disambiguation (i.e. it adds periods into sentences)\n",
    "\n",
    "## Instructions\n",
    "\n",
    "*NOTE: key inputs have now been made easier to edit/input with the google \"forms\" feature, look for those as things to change.*\n",
    "\n",
    "The two main things that need to be done to make this work are:\n",
    "1. Specify what the input filename and filepath are\n",
    "    * In this demo it is already specified for you (uses **requests** to get vid file from project repo)\n",
    "2. Adjust model main parameters\n",
    "    * with a GPU, should be stable @ **20** seconds\n",
    "    * with a CPU, bit of a trial-and-error process\n",
    "    * <font color='orange'> **Before running script, do Runtime->Change Runtime Type-> GPU in the top menu** </font>\n",
    "\n",
    "Sections where these parameters need to be updated are indicated in the file below (or see table of contents).\n",
    "\n",
    "** **\n",
    "\n",
    "<font color='orange'> This example was designed to be run in the Google Colab environment but should work locally with a few tweaks (i.e. get rid of google colab libraries) </font>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "zrT9iDtEX5Dl"
   },
   "source": [
    "want_to_download_results = True  # @param {type:\"boolean\"}"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2ES3PpiwLH9F",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "44dd38b3-0475-449a-8539-69531f12aafb"
   },
   "source": [
    "!nvidia-smi"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Tue Aug 17 05:12:29 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   45C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0Z5Kg0cd4z8"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aU0vhImmKeOc"
   },
   "source": [
    "%%capture\n",
    "\n",
    "!pip install pysbd\n",
    "!pip install transformers\n",
    "!pip install texthero\n",
    "!pip install wordninja\n",
    "!pip install yake\n",
    "!pip install symspellpy\n",
    "!pip install pycuda\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "!pip install moviepy --pre --upgrade\n",
    "!apt install ffmpeg\n",
    "!pip install -U tqdm\n",
    "!pip install -U neuspell\n",
    "!pip install clean-text[gpl]\n",
    "\n",
    "import math\n",
    "import os\n",
    "import pprint as pp\n",
    "import shutil\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import librosa\n",
    "import moviepy.editor as mp\n",
    "import moviepy\n",
    "import pandas as pd\n",
    "import pkg_resources\n",
    "import pysbd\n",
    "import texthero as hero\n",
    "import torch\n",
    "import wordninja\n",
    "import yake\n",
    "from natsort import natsorted\n",
    "from symspellpy import SymSpell\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
    "import pycuda.driver as cuda\n",
    "import psutil\n",
    "import humanize\n",
    "import GPUtil as GPU\n",
    "from tqdm.auto import tqdm\n",
    "import neuspell\n",
    "from tqdm.auto import tqdm\n",
    "from cleantext import clean"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHQz0UlnNTN4"
   },
   "source": [
    "# Function Definitions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrWTUJ_6FqZY"
   },
   "source": [
    "## generic"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9kMkHRpYdWEU"
   },
   "source": [
    "%%capture\n",
    "# for display in jupyter notebooks / colab only\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def set_css():\n",
    "    display(\n",
    "        HTML(\n",
    "            \"\"\"\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  \"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "get_ipython().events.register(\"pre_run_cell\", set_css)"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bZ5lPErWFtHy",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "8ab3050c-2075-4c2d-c12d-f69cb0f965cb"
   },
   "source": [
    "# define user functions\n",
    "\n",
    "\n",
    "def increase_font():\n",
    "    from IPython.display import Javascript\n",
    "\n",
    "    display(\n",
    "        Javascript(\n",
    "            \"\"\"\n",
    "  for (rule of document.styleSheets[0].cssRules){\n",
    "    if (rule.selectorText=='body') {\n",
    "      rule.style.fontSize = '24px'\n",
    "      break\n",
    "    }\n",
    "  }\n",
    "  \"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def reset_font():\n",
    "    from IPython.display import Javascript\n",
    "\n",
    "    display(\n",
    "        Javascript(\n",
    "            \"\"\"\n",
    "  for (rule of document.styleSheets[0].cssRules){\n",
    "    if (rule.selectorText=='body') {\n",
    "      rule.style.fontSize = '14px'\n",
    "      break\n",
    "    }\n",
    "  }\n",
    "  \"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def corr(s):\n",
    "    # adds space after period if there isn't one\n",
    "    # removes extra spaces\n",
    "    return re.sub(r\"\\.(?! )\", \". \", re.sub(r\" +\", \" \", s))\n",
    "\n",
    "\n",
    "def cleantxt_wrap(ugly_text):\n",
    "    # a wrapper for clean text with options different than default\n",
    "\n",
    "    # https://pypi.org/project/clean-text/\n",
    "    cleaned_text = clean(\n",
    "        ugly_text,\n",
    "        fix_unicode=True,  # fix various unicode errors\n",
    "        to_ascii=True,  # transliterate to closest ASCII representation\n",
    "        lower=True,  # lowercase text\n",
    "        no_line_breaks=True,  # fully strip line breaks as opposed to only normalizing them\n",
    "        no_urls=True,  # replace all URLs with a special token\n",
    "        no_emails=True,  # replace all email addresses with a special token\n",
    "        no_phone_numbers=True,  # replace all phone numbers with a special token\n",
    "        no_numbers=False,  # replace all numbers with a special token\n",
    "        no_digits=False,  # replace all digits with a special token\n",
    "        no_currency_symbols=True,  # replace all currency symbols with a special token\n",
    "        no_punct=True,  # remove punctuations\n",
    "        replace_with_punct=\"\",  # instead of removing punctuations you may replace them\n",
    "        replace_with_url=\"<URL>\",\n",
    "        replace_with_email=\"<EMAIL>\",\n",
    "        replace_with_phone_number=\"<PHONE>\",\n",
    "        replace_with_number=\"<NUM>\",\n",
    "        replace_with_digit=\"0\",\n",
    "        replace_with_currency_symbol=\"<CUR>\",\n",
    "        lang=\"en\",  # set to 'de' for German special handling\n",
    "    )\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def beautify_filename(filename, num_words=20, start_reverse=False, word_separator=\"_\"):\n",
    "    # takes a filename stored as text, removes extension, separates into X words ...\n",
    "    # and returns a nice filename with the words separateed by\n",
    "    # useful for when you are reading files, doing things to them, and making new files\n",
    "\n",
    "    filename = str(filename)\n",
    "    index_file_Ext = filename.rfind(\".\")\n",
    "    current_name = str(filename)[:index_file_Ext]  # get rid of extension\n",
    "    clean_name = cleantxt_wrap(current_name)  # wrapper with custom defs\n",
    "    file_words = wordninja.split(clean_name)\n",
    "    # splits concatenated text into a list of words based on common word freq\n",
    "    if len(file_words) <= num_words:\n",
    "        num_words = len(file_words)\n",
    "\n",
    "    if start_reverse:\n",
    "        t_file_words = file_words[-num_words:]\n",
    "    else:\n",
    "        t_file_words = file_words[:num_words]\n",
    "\n",
    "    pretty_name = word_separator.join(t_file_words)  # see function argument\n",
    "\n",
    "    # NOTE IT DOES NOT RETURN THE EXTENSION\n",
    "    return pretty_name[\n",
    "        : (len(pretty_name) - 1)\n",
    "    ]  # there is a space always at the end, so -1\n",
    "\n",
    "\n",
    "def quick_keys(\n",
    "    filename, filepath, max_ngrams=3, num_keywords=20, save_db=False, verbose=False\n",
    "):\n",
    "    # uses YAKE to quickly determine keywords in a text file. Saves Keywords and YAKE score (0 means very important) in\n",
    "    # an excel file (from a dataframe)\n",
    "    # yes, the double entendre is intended.\n",
    "    file = open(join(filepath, filename), \"r\", encoding=\"utf-8\", errors=\"ignore\")\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "\n",
    "    language = \"en\"\n",
    "    deduplication_threshold = 0.3  # technically a hyperparameter\n",
    "    custom_kw_extractor = yake.KeywordExtractor(\n",
    "        lan=language,\n",
    "        n=max_ngrams,\n",
    "        dedupLim=deduplication_threshold,\n",
    "        top=num_keywords,\n",
    "        features=None,\n",
    "    )\n",
    "    yake_keywords = custom_kw_extractor.extract_keywords(text)\n",
    "    phrase_db = pd.DataFrame(yake_keywords)\n",
    "    if verbose:\n",
    "        print(\"YAKE keywords are: \\n\", yake_keywords)\n",
    "        print(\"dataframe looks like: \\n\")\n",
    "        pp.pprint(phrase_db.head())\n",
    "\n",
    "    if len(phrase_db) == 0:\n",
    "        print(\"warning - no phrases were able to be extracted... \")\n",
    "        return None\n",
    "\n",
    "    phrase_db.columns = [\"key_phrase\", \"YAKE_sore\"]\n",
    "\n",
    "    # add a column for how many words the phrases contain\n",
    "    yake_kw_len = []\n",
    "    yake_kw_freq = []\n",
    "    for entry in yake_keywords:\n",
    "        entry_wordcount = len(str(entry).split(\" \")) - 1\n",
    "        yake_kw_len.append(entry_wordcount)\n",
    "\n",
    "    for index, row in phrase_db.iterrows():\n",
    "        search_term = row[\"key_phrase\"]\n",
    "        entry_freq = text.count(str(search_term))\n",
    "        yake_kw_freq.append(entry_freq)\n",
    "\n",
    "    word_len_series = pd.Series(yake_kw_len, name=\"No. Words in Phrase\")\n",
    "    word_freq_series = pd.Series(yake_kw_freq, name=\"Phrase Freq. in Text\")\n",
    "    phrase_db2 = pd.concat([phrase_db, word_len_series, word_freq_series], axis=1)\n",
    "    # add column names and save file as excel because CSVs suck\n",
    "    phrase_db2.columns = [\n",
    "        \"key_phrase\",\n",
    "        \"YAKE Score (Lower = More Important)\",\n",
    "        \"num_words\",\n",
    "        \"freq_in_text\",\n",
    "    ]\n",
    "\n",
    "    if save_db:\n",
    "        # saves individual file if user asks\n",
    "        yake_fname = (\n",
    "            beautify_filename(filename=filename, start_reverse=False)\n",
    "            + \"_top_phrases_YAKE.xlsx\"\n",
    "        )\n",
    "        phrase_db2.to_excel(join(filepath, yake_fname), index=False)\n",
    "\n",
    "    # print out top 10 keywords, or if desired num keywords less than 10, all of them\n",
    "    max_no_disp = 10\n",
    "    if num_keywords > max_no_disp:\n",
    "        num_phrases_disp = max_no_disp\n",
    "    else:\n",
    "        num_phrases_disp = num_keywords\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Top Key Phrases from YAKE, with max n-gram length: \", max_ngrams, \"\\n\")\n",
    "        pp.pprint(phrase_db2.head(n=num_phrases_disp))\n",
    "    else:\n",
    "        list_o_words = phrase_db2[\"key_phrase\"].to_list()\n",
    "        print(\"top 5 phrases are: \\n\")\n",
    "        if len(list_o_words) < 5:\n",
    "            pp.pprint(list_o_words)\n",
    "        else:\n",
    "            pp.pprint(list_o_words[:5])\n",
    "\n",
    "    return phrase_db2\n",
    "\n",
    "\n",
    "def digest_txt_directory(file_directory, identifer=\"\", verbose=False, make_folder=True):\n",
    "    run_date = datetime.now()\n",
    "    files_to_merge = natsorted(\n",
    "        [\n",
    "            f\n",
    "            for f in listdir(file_directory)\n",
    "            if isfile(join(file_directory, f)) & f.endswith(\".txt\")\n",
    "        ]\n",
    "    )\n",
    "    outfilename = (\n",
    "        \"Zealous_MERGED_words_\" + identifer + run_date.strftime(\"_%d%m%Y_%H\") + \".txt\"\n",
    "    )\n",
    "\n",
    "    og_wd = os.getcwd()\n",
    "    os.chdir(file_directory)\n",
    "\n",
    "    if make_folder:\n",
    "        folder_name = \"merged_txt_files\"\n",
    "        if not os.path.isdir(join(file_directory, folder_name)):\n",
    "            os.mkdir(\n",
    "                join(file_directory, folder_name)\n",
    "            )  # make a place to store outputs if one does not exist\n",
    "        output_loc = join(file_directory, folder_name)\n",
    "\n",
    "        outfilename = join(folder_name, outfilename)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"created new folder. new full path is: \\n\", output_loc)\n",
    "\n",
    "    count = 0\n",
    "    with open(outfilename, \"w\") as outfile:\n",
    "\n",
    "        for names in files_to_merge:\n",
    "\n",
    "            with open(names) as infile:\n",
    "                count += 1\n",
    "                outfile.write(\"Start of: \" + names + \"\\n\")\n",
    "                outfile.writelines(infile.readlines())\n",
    "\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "    print(\"Merged {} text files together.\".format(count))\n",
    "    if verbose:\n",
    "        print(\"the merged file is located at: \\n\", os.getcwd())\n",
    "    os.chdir(og_wd)\n",
    "\n",
    "\n",
    "def validate_output_directories(directory, verbose=False):\n",
    "\n",
    "    # checks and creates folders\n",
    "\n",
    "    t_folder_name = \"wav2vec2_sf_transcript\"\n",
    "    m_folder_name = \"wav2vec2_sf_metadata\"\n",
    "\n",
    "    # check if transcription folder exists. If not, create it\n",
    "    if not os.path.isdir(join(directory, t_folder_name)):\n",
    "        os.mkdir(\n",
    "            join(directory, t_folder_name)\n",
    "        )  # make a place to store outputs if one does not exist\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"needed to create the folder: {}. Its location is: \\n\".format(\n",
    "                    t_folder_name\n",
    "                ),\n",
    "                join(directory, t_folder_name),\n",
    "            )\n",
    "    t_path_full = join(directory, t_folder_name)\n",
    "\n",
    "    # check if metadata folder exists. If not, create it\n",
    "    if not os.path.isdir(join(directory, m_folder_name)):\n",
    "        os.mkdir(\n",
    "            join(directory, m_folder_name)\n",
    "        )  # make a place to store outputs if one does not exist\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"needed to create the folder: {}. Its location is: \\n\".format(\n",
    "                    m_folder_name\n",
    "                ),\n",
    "                join(directory, m_folder_name),\n",
    "            )\n",
    "\n",
    "    m_path_full = join(directory, m_folder_name)\n",
    "\n",
    "    output_locs = {\"t_out\": t_path_full, \"m_out\": m_path_full}\n",
    "\n",
    "    return output_locs\n",
    "\n",
    "\n",
    "def move2completed(from_dir, filename, new_folder=\"completed\", verbose=False):\n",
    "\n",
    "    # this is the better version\n",
    "    old_filepath = join(from_dir, filename)\n",
    "\n",
    "    new_filedirectory = join(from_dir, new_folder)\n",
    "\n",
    "    if not os.path.isdir(new_filedirectory):\n",
    "        os.mkdir(new_filedirectory)\n",
    "        if verbose:\n",
    "            print(\"created new directory for files at: \\n\", new_filedirectory)\n",
    "\n",
    "    new_filepath = join(new_filedirectory, filename)\n",
    "\n",
    "    try:\n",
    "        shutil.move(old_filepath, new_filepath)\n",
    "        print(\"successfully moved the file {} to */completed.\".format(filename))\n",
    "    except:\n",
    "        print(\n",
    "            \"ERROR! unable to move file to \\n{}. Please investigate\".format(\n",
    "                new_filepath\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "print(\"loaded all generic functions at: \", datetime.now())\n",
    "\n",
    "# create time log\n",
    "\n",
    "time_log = []\n",
    "time_log_desc = []\n",
    "time_log.append(time.perf_counter())\n",
    "time_log_desc.append(\"start\")"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "loaded all generic functions at:  2021-08-17 05:16:03.529439\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnN94mTXFw9d"
   },
   "source": [
    "## hardware monitoring"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jtgRuxdDGGqG",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "f9293117-3b8c-463d-b053-d5f8932022ba"
   },
   "source": [
    "def clear_GPU_cache(verbose=False):\n",
    "\n",
    "    GPUs = GPU.getGPUs()\n",
    "\n",
    "    if len(GPUs) > 0:\n",
    "        check_runhardware_torch()\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"\\nchecked and cleared cache\")\n",
    "    else:\n",
    "        print(\"\\nNo GPU being used :( time = \", datetime.now())\n",
    "    if verbose:\n",
    "        print(\"-----------End of Cache Clear----------------\")\n",
    "\n",
    "\n",
    "print(\"loaded all hardware functions at: \", datetime.now())\n",
    "\n",
    "\n",
    "def check_runhardware_torch(verbose=False):\n",
    "    # https://www.run.ai/guides/gpu-deep-learning/pytorch-gpu/\n",
    "\n",
    "    GPUs = GPU.getGPUs()\n",
    "\n",
    "    if len(GPUs) > 0:\n",
    "        if verbose:\n",
    "            print(\"\\n ------------------------------\")\n",
    "            print(\"Checking CUDA status for PyTorch\")\n",
    "\n",
    "        torch.cuda.init()\n",
    "\n",
    "        print(\"Cuda availability (PyTorch): \", torch.cuda.is_available())\n",
    "\n",
    "        # Get Id of default device\n",
    "        torch.cuda.current_device()\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"Name of GPU: \", torch.cuda.get_device_name(device=0)\n",
    "            )  # '0' is the id of your GPU\n",
    "            print(\"------------------------------\\n\")\n",
    "        return True\n",
    "\n",
    "    else:\n",
    "        print(\"No GPU being used :(\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def torch_validate_cuda(verbose=False):\n",
    "    GPUs = GPU.getGPUs()\n",
    "    num_gpus = len(GPUs)\n",
    "    try:\n",
    "        torch.cuda.init()\n",
    "        if not torch.cuda.is_available():\n",
    "            print(\n",
    "                \"WARNING - CUDA is not being used in processing - expect longer runtime\"\n",
    "            )\n",
    "            if verbose:\n",
    "                print(\"GPU util detects {} GPUs on your system\".format(num_gpus))\n",
    "    except:\n",
    "        print(\n",
    "            \"WARNING - unable to start CUDA. If you wanted to use a GPU, exit and check hardware.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def check_runhardware(verbose=False):\n",
    "    # ML package agnostic hardware check\n",
    "    GPUs = GPU.getGPUs()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n ------------------------------\")\n",
    "        print(\"Checking hardware with psutil\")\n",
    "    try:\n",
    "        gpu = GPUs[0]\n",
    "    except:\n",
    "        if verbose:\n",
    "            print(\"GPU not available - \", datetime.now())\n",
    "        gpu = None\n",
    "    process = psutil.Process(os.getpid())\n",
    "\n",
    "    CPU_load = psutil.cpu_percent()\n",
    "    if CPU_load > 0:\n",
    "        cpu_load_string = \"loaded at {} % |\".format(CPU_load)\n",
    "    else:\n",
    "        # the first time process.cpu_percent() is called it returns 0 which can be confusing\n",
    "        cpu_load_string = \"|\"\n",
    "    print(\n",
    "        \"\\nGen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available),\n",
    "        \" | Proc size: \" + humanize.naturalsize(process.memory_info().rss),\n",
    "        \" | {} CPUs \".format(psutil.cpu_count()),\n",
    "        cpu_load_string,\n",
    "    )\n",
    "\n",
    "    if len(GPUs) > 0 and GPUs is not None:\n",
    "        print(\n",
    "            \"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\\n\".format(\n",
    "                gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil * 100, gpu.memoryTotal\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        print(\"No GPU being used :(\", \"\\n-----------------\\n\")\n",
    "\n",
    "\n",
    "def only_clear_GPU_cache(verbose=False):\n",
    "\n",
    "    GPUs = GPU.getGPUs()\n",
    "\n",
    "    if len(GPUs) > 0:\n",
    "        torch.cuda.empty_cache()\n",
    "        if verbose:\n",
    "            print(\"\\nchecked and cleared cache\")\n",
    "    else:\n",
    "        print(\"\\nClearCache - No GPU being used :( time = \", datetime.now())\n",
    "\n",
    "\n",
    "# create time log\n",
    "\n",
    "time_log.append(time.perf_counter())\n",
    "time_log_desc.append(\"loaded hardware functions\")"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "loaded all hardware functions at:  2021-08-17 05:16:03.616676\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDk-_y6VFw-9"
   },
   "source": [
    "## for video conversion / transcription"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-xtpYd9tZhso",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "6298b184-455d-4bcc-e567-f94c3212ccc1"
   },
   "source": [
    "def convert_vidfile(\n",
    "    vidfilename,\n",
    "    start_time=0,\n",
    "    end_time=6969,\n",
    "    input_directory=\"\",\n",
    "    output_directory=\"\",\n",
    "    new_filename=\"\",\n",
    "):\n",
    "    # takes a video file and creates an audiofile with various parameters\n",
    "    # NOTE video filename is required\n",
    "    if len(input_directory) < 1:\n",
    "        my_clip = mp.VideoFileClip(vidfilename)\n",
    "    else:\n",
    "        my_clip = mp.VideoFileClip(join(input_directory, vidfilename))\n",
    "\n",
    "    if end_time == 6969:\n",
    "        modified_clip = my_clip.subclip(t_start=int(start_time * 60))\n",
    "    else:\n",
    "        modified_clip = my_clip.subclip(\n",
    "            t_start=int(start_time * 60), t_end=int(end_time * 60)\n",
    "        )\n",
    "\n",
    "    converted_filename = (\n",
    "        vidfilename[: (len(vidfilename) - 4)]\n",
    "        + \"-converted_\"\n",
    "        + datetime.now().strftime(\"day_%d_time_%H-%M-%S_\")\n",
    "        + \".wav\"\n",
    "    )\n",
    "    # update_filename\n",
    "    if len(new_filename) > 0:\n",
    "        converted_filename = new_filename\n",
    "\n",
    "    if len(output_directory) < 1:\n",
    "        modified_clip.audio.write_audiofile(converted_filename)\n",
    "    else:\n",
    "        # removed 'verbose=False,' from argument of function (removed from Dev)\n",
    "        modified_clip.audio.write_audiofile(\n",
    "            join(output_directory, converted_filename), logger=None\n",
    "        )\n",
    "\n",
    "    audio_conv_results = {\n",
    "        \"output_filename\": converted_filename,\n",
    "        \"output_folder\": output_directory,\n",
    "        \"clip_length\": modified_clip.duration,\n",
    "    }\n",
    "\n",
    "    return audio_conv_results\n",
    "\n",
    "\n",
    "def convert_vid_for_transcription(\n",
    "    vid2beconv, len_chunks, input_directory, output_directory\n",
    "):\n",
    "    # Oriented specifically for the \"wav2vec2\" model speech to text transcription\n",
    "    # takes a video file, turns it into .wav audio chunks of length <input> and stores them in a specific location\n",
    "    # TODO: add try/except clause in case the user already has an audio file the want to transcribe\n",
    "    my_clip = mp.VideoFileClip(join(input_directory, vid2beconv))\n",
    "    number_of_chunks = math.ceil(my_clip.duration / len_chunks)  # to get in minutes\n",
    "    print(\"converting into \" + str(number_of_chunks) + \" audio chunks\")\n",
    "    preamble = beautify_filename(vid2beconv)\n",
    "    outfilename_storage = []\n",
    "    print(\n",
    "        \"separating audio into chunks starting at \",\n",
    "        datetime.now().strftime(\"_%H.%M.%S\"),\n",
    "    )\n",
    "    update_incr = math.ceil(number_of_chunks / 10)\n",
    "\n",
    "    for i in tqdm(\n",
    "        range(number_of_chunks),\n",
    "        desc=\"Converting Video to Audio Chunks\",\n",
    "        total=number_of_chunks,\n",
    "    ):\n",
    "\n",
    "        start_time = i * len_chunks\n",
    "        if i == number_of_chunks - 1:\n",
    "            this_clip = my_clip.subclip(t_start=start_time)\n",
    "        else:\n",
    "            this_clip = my_clip.subclip(\n",
    "                t_start=start_time, t_end=(start_time + len_chunks)\n",
    "            )\n",
    "        this_filename = preamble + \"_run_\" + str(i) + \".wav\"\n",
    "        outfilename_storage.append(this_filename)\n",
    "\n",
    "        if this_clip.audio is not None:\n",
    "            # removed 'verbose=False,' from argument of function (removed from Dev)\n",
    "            this_clip.audio.write_audiofile(\n",
    "                join(output_directory, this_filename), logger=None\n",
    "            )\n",
    "        else:\n",
    "            print(\"\\n WARNING: chunk {} is empty / has no audio\".format(i))\n",
    "\n",
    "    print(\"Finished creating audio chunks at \", datetime.now().strftime(\"_%H.%M.%S\"))\n",
    "    print(\"Files are located in \", output_directory)\n",
    "    return outfilename_storage\n",
    "\n",
    "\n",
    "def transcribe_video_wav2vec(\n",
    "    transcription_model, directory, vid_clip_name, chunk_length_seconds\n",
    "):\n",
    "    # this is the same process as used in the single video transcription, now as a function. Note that spell correction\n",
    "    # and keyword extraction are now done separately in the script\n",
    "    # user needs to pass in: the model, the folder the video is in, and the name of the video\n",
    "    output_path_full = directory\n",
    "\n",
    "    # Split Video into Audio Chunks-----------------------------------------------\n",
    "\n",
    "    print(\"\\n============================================================\")\n",
    "    print(\"Converting video to audio for file: \", vid_clip_name)\n",
    "    print(\"============================================================\\n\")\n",
    "\n",
    "    # create audio chunk folder\n",
    "    output_folder_name = \"audio_chunks\"\n",
    "    if not os.path.isdir(join(directory, output_folder_name)):\n",
    "        os.mkdir(\n",
    "            join(directory, output_folder_name)\n",
    "        )  # make a place to store outputs if one does not exist\n",
    "    path2audiochunks = join(directory, output_folder_name)\n",
    "    chunk_directory = convert_vid_for_transcription(\n",
    "        vid2beconv=vid_clip_name,\n",
    "        input_directory=directory,\n",
    "        len_chunks=chunk_length_seconds,\n",
    "        output_directory=path2audiochunks,\n",
    "    )\n",
    "\n",
    "    print(\"\\n============================================================\")\n",
    "    print(\n",
    "        \"converted video to audio. About to start transcription loop for file: \",\n",
    "        vid_clip_name,\n",
    "    )\n",
    "    print(\"============================================================\\n\")\n",
    "    torch_validate_cuda()\n",
    "    check_runhardware()\n",
    "    time_log.append(time.perf_counter())\n",
    "    time_log_desc.append(\"converted video to audio\")\n",
    "    full_transcription = []\n",
    "    before_loop_st = time.perf_counter()\n",
    "    GPU_update_incr = math.ceil(len(chunk_directory) / 2)\n",
    "\n",
    "    # Load audio chunks by name, pass into model, append output text-----------------------------------------------\n",
    "\n",
    "    for audio_chunk in tqdm(\n",
    "        chunk_directory,\n",
    "        total=len(chunk_directory),\n",
    "        desc=\"wav2vec2 model for \" + vid_clip_name,\n",
    "    ):\n",
    "\n",
    "        current_loc = chunk_directory.index(audio_chunk)\n",
    "        if (current_loc % GPU_update_incr == 0) and (GPU_update_incr != 0):\n",
    "            # provide update on GPU usage\n",
    "            check_runhardware()\n",
    "\n",
    "        # load dat chunk\n",
    "        audio_input, rate = librosa.load(join(path2audiochunks, audio_chunk), sr=16000)\n",
    "        # MODEL\n",
    "        device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        input_values = tokenizer(\n",
    "            audio_input, return_tensors=\"pt\", padding=\"longest\", truncation=True\n",
    "        ).input_values.to(device)\n",
    "        transcription_model = transcription_model.to(device)\n",
    "        logits = transcription_model(input_values).logits\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = str(tokenizer.batch_decode(predicted_ids)[0])\n",
    "        full_transcription.append(transcription + \"\\n\")\n",
    "        # empty memory so you don't overload the GPU\n",
    "        del input_values\n",
    "        del logits\n",
    "        del predicted_ids\n",
    "        del audio_input\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(\n",
    "        \"\\nFinished audio transcription of \"\n",
    "        + vid_clip_name\n",
    "        + \" and now saving metrics.\"\n",
    "    )\n",
    "\n",
    "    # build metadata log -------------------------------------------------\n",
    "    mdata = []\n",
    "    mdata.append(\"original file name: \" + vid_clip_name + \"\\n\")\n",
    "    mdata.append(\n",
    "        \"number of recorded audio chunks: \"\n",
    "        + str(len(chunk_directory))\n",
    "        + \" of lengths seconds each\"\n",
    "        + str(chunk_length_seconds)\n",
    "        + \"\\n\"\n",
    "    )\n",
    "    approx_input_len = (len(chunk_directory) * chunk_length_seconds) / 60\n",
    "    mdata.append(\n",
    "        \"approx {0:3f}\".format(approx_input_len) + \" minutes of input audio \\n\"\n",
    "    )\n",
    "    mdata.append(\n",
    "        \"transcription date: \"\n",
    "        + datetime.now().strftime(\"date_%d_%m_%Y_time_%H-%M-%S\")\n",
    "        + \"\\n\"\n",
    "    )\n",
    "    full_text = \" \".join(full_transcription)\n",
    "    transcript_length = len(full_text)\n",
    "    mdata.append(\n",
    "        \"length of transcribed text: \" + str(transcript_length) + \" characters \\n\"\n",
    "    )\n",
    "    t_word_count = len(full_text.split(\" \"))\n",
    "    mdata.append(\n",
    "        \"total word count: \" + str(t_word_count) + \" words (based on spaces) \\n\"\n",
    "    )\n",
    "\n",
    "    # delete audio chunks in folder -------------------------------------------------\n",
    "    # TODO: add try/except for deleting folder as not technically needed to achieve goal\n",
    "    shutil.rmtree(path2audiochunks)\n",
    "    print(\"\\nDeleted Audio Chunk Folder + Files\")\n",
    "\n",
    "    # compile results -------------------------------------------------\n",
    "    transcription_results = {\n",
    "        \"audio_transcription\": full_transcription,\n",
    "        \"metadata\": mdata,\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        \"\\nFinished transcription successfully for \"\n",
    "        + vid_clip_name\n",
    "        + \" at \"\n",
    "        + datetime.now().strftime(\"date_%d_%m_%Y_time_%H-%M-%S\")\n",
    "    )\n",
    "    return transcription_results\n",
    "\n",
    "\n",
    "print(\"loaded all transcription specific functions at: \", datetime.now())"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "loaded all transcription specific functions at:  2021-08-17 05:16:03.870653\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_Axg8hVc8L9"
   },
   "source": [
    "## spell correction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N9-usQDpc9db",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "outputId": "538c65ca-0c9a-4a43-8f3a-1ab2a6c6ff9b"
   },
   "source": [
    "%%capture\n",
    "# neuspell prints out the whole upon definition, hence ^ jupyter magic\n",
    "\n",
    "def symspell_file(filepath, filename, dist=2, keep_numb_words=True, create_folder=True, save_metrics=False,\n",
    "                  verbose=False):\n",
    "    # given a text (has to be text) file, reads the file, autocorrects any words it deems misspelled, saves as new file\n",
    "    # it can store the new file in a sub-folder it creates as needed\n",
    "    # distance represents how far it searches for a better spelling. higher dist = higher RT.\n",
    "    # https://github.com/mammothb/symspellpy\n",
    "\n",
    "    script_start_time = time.perf_counter()\n",
    "    sym_spell = SymSpell(max_dictionary_edit_distance=dist, prefix_length=7)\n",
    "    print(\"\\nPySymSpell - Starting to correct the file: \", filename)\n",
    "    # ------------------------------------\n",
    "\n",
    "    dictionary_path = pkg_resources.resource_filename(\n",
    "        \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
    "    bigram_path = pkg_resources.resource_filename(\n",
    "        \"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\")\n",
    "    # term_index is the column of the term and count_index is the\n",
    "    # column of the term frequency\n",
    "    sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "    sym_spell.load_bigram_dictionary(bigram_path, term_index=0, count_index=2)\n",
    "\n",
    "    # ------------------------------------\n",
    "    file = open(join(filepath, filename), 'r', encoding=\"utf-8\", errors='ignore')\n",
    "    textlines = file.readlines()  # return a list\n",
    "    file.close()\n",
    "\n",
    "    if create_folder:\n",
    "        # create a folder\n",
    "        output_folder_name = \"auto-corrected\" \n",
    "        if not os.path.isdir(join(filepath, output_folder_name)):\n",
    "            os.mkdir(join(filepath, output_folder_name))  # make a place to store outputs if one does not exist\n",
    "        filepath = join(filepath, output_folder_name)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"loaded text with {0:6d} lines \".format(len(textlines)))\n",
    "\n",
    "    corrected_list = []\n",
    "\n",
    "    # iterate through list of lines. Pass each line to be corrected. \n",
    "    #Append / sum results from each line till done\n",
    "    for line in textlines:\n",
    "        if line == \"\":\n",
    "            # blank line, skip to next run\n",
    "            continue\n",
    "\n",
    "        # correct the line of text using spellcorrect_line() which returns a dictionary\n",
    "        suggestions = sym_spell.lookup_compound(phrase=line, max_edit_distance=dist, \n",
    "                                                ignore_non_words=keep_numb_words,\n",
    "                                                ignore_term_with_digits=keep_numb_words)\n",
    "        all_sugg_for_line = []\n",
    "        for suggestion in suggestions:\n",
    "            all_sugg_for_line.append(suggestion.term)\n",
    "\n",
    "        # append / sum / log results from correcting the line\n",
    "\n",
    "        corrected_list.append(' '.join(all_sugg_for_line) + \"\\n\")\n",
    "\n",
    "    # finished iterating through lines. Now sum total metrics\n",
    "\n",
    "    corrected_doc = \"\".join(corrected_list)\n",
    "    corrected_fname = \"Corrected_SSP_\" + beautify_filename(filename, \n",
    "                                                           num_words=10, start_reverse=False) + \".txt\"\n",
    "\n",
    "    # proceed to saving\n",
    "    file_out = open(join(filepath, corrected_fname), 'w',\n",
    "                    encoding=\"utf-8\", errors='ignore')\n",
    "    file_out.writelines(corrected_doc)\n",
    "    file_out.close()\n",
    "\n",
    "    # report RT\n",
    "    if verbose:\n",
    "        script_rt_m = (time.perf_counter() - script_start_time) / 60\n",
    "        print(\"RT for this file was {0:5f} minutes\".format(script_rt_m))\n",
    "        print(\"output folder for this transcription is: \\n\", \n",
    "              filepath)\n",
    "\n",
    "    print(\"Done correcting \", filename, \" at time: \", \n",
    "          datetime.now().strftime(\"%H:%M:%S\"), \"\\n\")\n",
    "\n",
    "    corr_file_Data = {\n",
    "        \"corrected_ssp_text\": corrected_doc,\n",
    "        \"corrected_ssp_fname\": corrected_fname,\n",
    "        \"output_path\": filepath,\n",
    "    }\n",
    "    return corr_file_Data\n",
    "\n",
    "\n",
    "# preload defaults\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=3, prefix_length=7)\n",
    "\n",
    "dictionary_path = pkg_resources.resource_filename(\n",
    "        \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
    "bigram_path = pkg_resources.resource_filename(\n",
    "        \"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\")\n",
    "# term_index is the column of the term and count_index is the\n",
    "# column of the term frequency\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "sym_spell.load_bigram_dictionary(bigram_path, term_index=0, count_index=2)\n",
    "\n",
    "print(\"loaded defaults - \", datetime.now())\n",
    "\n",
    "def symspell_freetext(textlines, dist=3, keep_numb_words=True, verbose=False,\n",
    "                      d_path=dictionary_path, b_path=bigram_path, default=sym_spell):\n",
    "    # https://github.com/mammothb/symspellpy\n",
    "\n",
    "    if dist != 3:\n",
    "\n",
    "        # have to recreate object each time because doesn't match pre-built\n",
    "\n",
    "        sym_spell = SymSpell(max_dictionary_edit_distance=dist, prefix_length=7)\n",
    "        sym_spell.load_dictionary(d_path, term_index=0, count_index=1)\n",
    "        sym_spell.load_bigram_dictionary(b_path, term_index=0, count_index=2)\n",
    "    else:\n",
    "        sym_spell=default\n",
    "\n",
    "    corrected_list = []\n",
    "\n",
    "    if type(textlines) == str:\n",
    "        textlines = [textlines] # put in a list if a string\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nStarting to correct text with {0:6d} lines \".format(len(textlines)))\n",
    "        print(\"the type of textlines var is \",type(textlines))\n",
    "\n",
    "    # iterate through list of lines. Pass each line to be corrected. Append / sum results from each line till done\n",
    "    for line_obj in textlines:\n",
    "        line = ''.join(line_obj) \n",
    "        if verbose:\n",
    "            print(\"line {} in the text is: \".format(textlines.index(line_obj)))\n",
    "            pp.pprint(line) \n",
    "        if line == \"\":\n",
    "            # blank line, skip to next run\n",
    "            continue\n",
    "\n",
    "        suggestions = sym_spell.lookup_compound(phrase=line, max_edit_distance=dist, \n",
    "                                                ignore_non_words=keep_numb_words,\n",
    "                                                ignore_term_with_digits=keep_numb_words)\n",
    "        all_sugg_for_line = []\n",
    "        for suggestion in suggestions:\n",
    "            all_sugg_for_line.append(suggestion.term)\n",
    "\n",
    "        # append / sum / log results from correcting the line\n",
    "\n",
    "        corrected_list.append(' '.join(all_sugg_for_line) + \"\\n\")\n",
    "\n",
    "    # join corrected text\n",
    "\n",
    "    corrected_text = \"\".join(corrected_list)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Finished correcting w/ symspell at time: \", datetime.now(), \"\\n\")\n",
    "\n",
    "    return corrected_text\n",
    "\n",
    "\n",
    "# START OF NEUSPELL\n",
    "\n",
    "checker = neuspell.SclstmbertChecker()\n",
    "checker.from_pretrained()\n",
    "\n",
    "def neuspell_freetext(textlines, verbose=False):\n",
    "\n",
    "    corrected_list = []\n",
    "\n",
    "    if type(textlines) == str:\n",
    "        textlines = [textlines] # put in a list if a string\n",
    "\n",
    "    # iterate through list of lines. Pass each line to be corrected. Append / sum results from each line till done\n",
    "    for line_obj in textlines:\n",
    "        line = ''.join(line_obj) \n",
    "\n",
    "        if verbose:\n",
    "            print(\"line {} in the text is: \".format(textlines.index(line_obj)))\n",
    "            pp.pprint(line) \n",
    "        if line == \"\" or (len(line) <= 5):\n",
    "            # blank line, skip to next run\n",
    "            continue\n",
    "\n",
    "        line = line.lower()\n",
    "        corrected_text = checker.correct_strings([line])\n",
    "        corrected_text_f = \" \".join(corrected_text)\n",
    "\n",
    "        corrected_list.append(corrected_text_f + \"\\n\")\n",
    "\n",
    "    # join corrected text\n",
    "\n",
    "    corrected_text = \" \".join(corrected_list)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Finished correcting w/ neuspell at time: \", datetime.now(), \"\\n\")\n",
    "\n",
    "    return corrected_text\n",
    "\n",
    "def SBD_freetext(text, verbose=False):\n",
    "    # input should be STRING\n",
    "    # use pysbd to segment \n",
    "\n",
    "    if isinstance(text, list):\n",
    "        print(\"Warning, input ~text~ has type {}. Will convert to str\".format(type(text)))\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    seg = pysbd.Segmenter(language=\"en\", clean=True)\n",
    "    sentences = []\n",
    "    sentences = seg.segment(text)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"input text of {} words was split into \".format(len(text.split(\" \"))),\n",
    "              len(sentences), \"sentences\")\n",
    "\n",
    "    # take segments and make them sentences\n",
    "    \n",
    "    capitalized = []\n",
    "    for sentence in sentences:\n",
    "        if sentence and sentence.strip():\n",
    "            # ensure that the line is not all spaces\n",
    "            first_letter = sentence[0].upper()\n",
    "            rest = sentence[1:]\n",
    "            capitalized.append(first_letter + rest)\n",
    "\n",
    "    seg_and_capital = \". \".join(capitalized)\n",
    "\n",
    "    return seg_and_capital\n",
    "\n",
    "print(\"loaded all spell correction functions at: \", datetime.now())\n",
    "\n"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NJK7YP72Riz"
   },
   "source": [
    "# Load Files and Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rZXO1z1fpnV"
   },
   "source": [
    "Note that you can also connect to a google drive folder if you want to transcribe a large video file or several video files (described in the \"multi\" script [here](https://colab.research.google.com/drive/1UMCSh9XdvUABjDJpFUrHPj4uy3Cc26DC?usp=sharing)\n",
    "\n",
    "The code to do so would be as follows:\n",
    "\n",
    "```\n",
    "# create interface to upload / interact with google drive and video files\n",
    "\n",
    "from google.colab import files\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# google will ask you to click link, approve, and paste code\n",
    "\n",
    "# after authentication, you can work using the path \"/content/drive/My Drive\"\n",
    "# if it works it will say \"Mounted at /content/drive\"\n",
    "\n",
    "# part 2: specify where in the drive the files are located\n",
    "\n",
    "filename = \"President John F. Kennedy's Peace Speech.mp4\"\n",
    "filepath = \"/content/drive/My Drive/Programming/vid2cleantxt_colabfiles\"\n",
    "\n",
    "print('Will use the following as directory/file: ')\n",
    "pp.pprint(''.join([filepath, filename]))\n",
    "\n",
    "```\n",
    "\n",
    "** **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJJ4BVpL9ixu"
   },
   "source": [
    "## Instructions P1: Input File Details\n",
    "\n",
    "Specify the URL of the file you want to transcribe. This script downloads the file from the vid2clntext github repo and saves it to the VM's working directory using the **requests** library. \n",
    "\n",
    "- the URL can be changed to anything as long as it downloads a video file (and the filename is updated as relevant)\n",
    "\n",
    "<font color='orange'> update the **input_path** variable to a custom filepath if desired (i.e. you are running this locally) </font>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "abci8m6CSN50",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "outputId": "de6be3d5-26ad-418a-cda0-f82d4bce173e"
   },
   "source": [
    "filename = \"JFK_rice_moon_speech.mp4\"  # @param {type:\"string\"}\n",
    "URL = \"https://github.com/pszemraj/vid2cleantxt/raw/master/example_JFK_speech/TEST_folder_edition/JFK_rice_moon_speech.mp4\"  # @param {type:\"string\"}"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b-nwIm1zmHlc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "outputId": "b091f9c7-80bf-4fc4-d1e9-2a5fccd32381"
   },
   "source": [
    "# using requests\n",
    "import requests\n",
    "\n",
    "file_loc = join(os.getcwd(), \"transcription\")\n",
    "os.makedirs(file_loc, exist_ok=True)\n",
    "input_path = os.path.join(file_loc, filename)  # filename taken from above\n",
    "print(\"starting to download and save file \")\n",
    "r = requests.get(URL, allow_redirects=True)\n",
    "open(input_path, \"wb\").write(r.content)  # URL taken from above input\n",
    "print(\"successfully saved \", filename, \" - \", datetime.now())"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "starting to download and save file \n",
      "successfully saved  JFK_rice_moon_speech.mp4  -  2021-08-17 05:17:23.657168\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bV3ov-0Z_PXf"
   },
   "source": [
    "## Instructions P2: Update chunk_length\n",
    "\n",
    "Update the variable 'chunk_length' to your use case. A good value is one that doesn't cause Colab to crash and is greater than a sentence length (for context, grammar purposes).\n",
    "\n",
    " \n",
    "\n",
    "- If Colab is using a GPU, 20 seconds should be fine. If Colab is only able to use a CPU, may need to be decreased. \n",
    "\n",
    "- You can use the `!nvidia-smi` command in a cell to check GPU status.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "*NOTE* recommended value for `chunk_length`  depends on which GPU Colab assigns you. A chunk length of 20 works on a Tesla K-80, which is typically what the free version gets allocated. A chunk length of 30 works on a Tesla P-100 16gb, standard for Colab Pro. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "SjqqYc-YSsOm",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "outputId": "c06a2383-b692-4a2b-b315-0bdb0331cf8a"
   },
   "source": [
    "chunk_length = 20  # @param {type:\"number\"}"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k_gAUG_9aK-d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323,
     "referenced_widgets": [
      "dfa4cec8e4ae4d6b8ba181b8271f5f12",
      "36301db4e912457fb2ad3b28f7a63179",
      "02f7bcad7a034aedaff12487945c609b",
      "1a34c092d8514655a5a7d95c8881f18d",
      "9aa06210e96b48a5bf288bf357f58aa9",
      "d627fd9297644f128554e0300982de7a",
      "6958d235a28241eea3865f4b6fa82104",
      "443bd4a8bf184e2d992d46444a5159f1",
      "8d6139109f2b41fe9068ea9645409d8b",
      "0ed860e92b0b4befb286ca705d831e82",
      "c31cb89839fd4b428da58d3e122d48d1",
      "63ea06b651d54b3cbca55458af1a0e30",
      "948040264bee418a96aacf5ae7b7cbbc",
      "3f4f0c5b80814d52b7f33b8833e7766c",
      "5682b194994f4dda977c448a11b1ad17",
      "04986152213344929bae81cdd88da197",
      "cbd34e24ad1445389efc51fc54f6e349",
      "0461719f0ee449c8a02efa71e1e7d61f",
      "dd2c514c869b4b67a6c9e43bd2f377af",
      "e9ab096b4a634f3ebd8512d775285257",
      "2cc720f566c14efc8c5f059d0e368e36",
      "14fc86d70a3d4bb09ffa1d3acc4ad3e6",
      "0656f1d7f415416db150b597e92fa339",
      "e46d1e6b584a4e3292a835239243a8a4",
      "a0041df82ede426aac32e932efa32d26",
      "b214c360d2ac438b9304f99f4c8be92e",
      "70bf93b0c19245ba944107328f9c42b8",
      "8e9675a3401043869808862204ad6122",
      "69e47adca28b43fe816b11ea73311ae7",
      "926a0035f13b493088f888f7e78eb8f4",
      "677d881f99764dee92e71f4100f649c4",
      "87861e3f433a4e4eabf84c3c145a3a32",
      "1741e4927f674a89bbe7602fcc15668e",
      "76122e8529ab4cdb9d3bcb6e04eeceab",
      "f0ae2fd16d3e4db78d79f199717c2443",
      "5f87457338ef4e3a96d0319342565707",
      "a431840ff75c4e1db36858079e0b5e5f",
      "cbc35df79bf64370ae00fb1a774dc834",
      "ea521fcea80a46d685a130f45da0b11b",
      "a2e3ae60c66149a490108b7fa5901efe",
      "f69ca3251c7e4b38ad2153b6fe8a7ef1",
      "c5734af7f84c43a2b7e2ba8ee250570e",
      "81203315409348c6955a025774e10151",
      "2243b131c8014415b466619a116439a2",
      "0263e1f539cc4aa6b9ad9ac354454d47",
      "d4613be8952a4e24802460eba2311798",
      "92ecae1b4161419da4c32b63736b7892",
      "9e20c764f02a48908afafc6e962f2277",
      "8c33bbda09614b5f813e2381060b1e0d",
      "7db51c8129934ebc92b7489efe009f4d",
      "c8574c98f6ff498d8b3c63d8fd8e78a6",
      "3c3af295d4f24f6f8c301b7fe63213d6",
      "f407ca06b5e64bf79c09e4a00776db9c",
      "5bac7f603d824c9983997f42e602772e",
      "0d838106c8a7478bb13b3e3e652c322b"
     ]
    },
    "outputId": "91abda01-3ee0-406b-c755-80d80d8f3f1a"
   },
   "source": [
    "# load huggingface model\n",
    "time_log.append(time.perf_counter())\n",
    "time_log_desc.append(\"starting to load model\")\n",
    "\n",
    "# load pretrained model\n",
    "wav2vec2_model = \"facebook/wav2vec2-large-960h-lv60-self\"\n",
    "# wav2vec2_model = \"facebook/wav2vec2-base-960h\" # faster+smaller, less accurate\n",
    "print(\"\\nPreparing to load model: \" + wav2vec2_model)\n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(wav2vec2_model)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(wav2vec2_model)\n",
    "\n",
    "# (in seconds) if model fails to work or errors out (and there isn't some other\n",
    "# obvious error, reduce chunk_length.\n",
    "\n",
    "print(\"loaded the following model:\", wav2vec2_model, \" at \", datetime.now())\n",
    "time_log.append(time.perf_counter())\n",
    "time_log_desc.append(\"loaded model\")"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing to load model: facebook/wav2vec2-large-960h-lv60-self\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa4cec8e4ae4d6b8ba181b8271f5f12",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ea06b651d54b3cbca55458af1a0e30",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/162 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0656f1d7f415416db150b597e92fa339",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76122e8529ab4cdb9d3bcb6e04eeceab",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.61k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:419: FutureWarning:\n",
      "\n",
      "The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0263e1f539cc4aa6b9ad9ac354454d47",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "loaded the following model: facebook/wav2vec2-large-960h-lv60-self  at  2021-08-17 05:18:06.131490\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zybapeYW_4uw"
   },
   "source": [
    "# Run Transformer Model (wav2vec2)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7EkpWuk3bmpP",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682,
     "referenced_widgets": [
      "caad4d5707b94fbbb1840b7c8bf60580",
      "469616e95d2648e7ae7fc406dcc93c09",
      "0a21b37adbd947ceb3304819b969d9e0",
      "6f39d81448d848d497630193bfc0612d",
      "674e9d27d8b7447e8f72c5ff86d40900",
      "4f86feb219df4692a4361e07eb072147",
      "165667e75fe841fca15e1e783cfee911",
      "88f548f1ec7d48aba62500e9b0b8431f",
      "54c0ddb5c31a4cf1844ed03554d313c2",
      "b922fbd5c9e94bf3b659b1a874056fb0",
      "3b789227150246c9a584ec1b74560b76",
      "bd862f1ef58e4a59a4238f05a841c38c",
      "20d9b9d3d0c6401a90c100bec9d6652c",
      "e1116c3d8e8c4e6fa531b6cbbd29f54b",
      "7bda4e420bb4484292ddec3d6db3fb5b",
      "9bce9c338c5c497092901fbef6c14e81",
      "72702c2e3b094fe8830a626454e69f3e",
      "1b70355b3f2f4b19acaa11f23a35e1f7",
      "715724e299b14424b977973b847bb095",
      "411998ca28dd4be7a174c6dc0f12a464",
      "ddcf632379db417e959ff74fc76ac868",
      "68332b0b56cd4c6191a31d7263f60cf9"
     ]
    },
    "outputId": "4bb0d5df-694f-4c32-fb2a-e77578e39848"
   },
   "source": [
    "# load videos, run through the model\n",
    "st = time.perf_counter()\n",
    "time_log.append(st)\n",
    "time_log_desc.append(\"starting transcription\")\n",
    "\n",
    "t_results = transcribe_video_wav2vec(\n",
    "    transcription_model=model,\n",
    "    directory=file_loc,\n",
    "    vid_clip_name=filename,\n",
    "    chunk_length_seconds=chunk_length,\n",
    ")\n",
    "end_t = time.perf_counter()\n",
    "time_log.append(end_t)\n",
    "time_log_desc.append(\"finished transcription\")\n",
    "\n",
    "# t_results is a dictonary containing the transcript and associated metadata\n",
    "full_transcription = t_results.get(\"audio_transcription\")\n",
    "metadata = t_results.get(\"metadata\")\n",
    "\n",
    "print(\"completed transcription in {} minutes\".format(round((end_t - st) / 60, 2)))"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Converting video to audio for file:  JFK_rice_moon_speech.mp4\n",
      "============================================================\n",
      "\n",
      "converting into 9 audio chunks\n",
      "separating audio into chunks starting at  _05.18.07\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caad4d5707b94fbbb1840b7c8bf60580",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Converting Video to Audio Chunks:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "Finished creating audio chunks at  _05.18.11\n",
      "Files are located in  /content/transcription/audio_chunks\n",
      "\n",
      "============================================================\n",
      "converted video to audio. About to start transcription loop for file:  JFK_rice_moon_speech.mp4\n",
      "============================================================\n",
      "\n",
      "\n",
      "Gen RAM Free: 24.3 GB  | Proc size: 6.2 GB  | 4 CPUs  loaded at 20.8 % |\n",
      "GPU RAM Free: 16278MB | Used: 2MB | Util   0% | Total 16280MB\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd862f1ef58e4a59a4238f05a841c38c",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "wav2vec2 model for JFK_rice_moon_speech.mp4:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "Gen RAM Free: 24.3 GB  | Proc size: 6.2 GB  | 4 CPUs  loaded at 39.1 % |\n",
      "GPU RAM Free: 16278MB | Used: 2MB | Util   0% | Total 16280MB\n",
      "\n",
      "\n",
      "Gen RAM Free: 24.1 GB  | Proc size: 6.6 GB  | 4 CPUs  loaded at 20.6 % |\n",
      "GPU RAM Free: 14113MB | Used: 2167MB | Util  13% | Total 16280MB\n",
      "\n",
      "\n",
      "Finished audio transcription of JFK_rice_moon_speech.mp4 and now saving metrics.\n",
      "\n",
      "Deleted Audio Chunk Folder + Files\n",
      "\n",
      "Finished transcription successfully for JFK_rice_moon_speech.mp4 at date_17_08_2021_time_05-18-31\n",
      "completed transcription in 0.42 minutes\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyFxqjynqR8s"
   },
   "source": [
    "# Post-Transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAlsOjR8AD7R"
   },
   "source": [
    "## Spell Check, SBD, Keywords\n",
    "\n",
    "If you got to here, your colab file was able to run the model and transcribe it. Now a little cleaning up, then done."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5ECdmK3tjP4L",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "outputId": "691fa4a0-28b7-456f-da33-61ba857626d3"
   },
   "source": [
    "# create output locations and store full transcription\n",
    "\n",
    "time_log.append(time.perf_counter())\n",
    "time_log_desc.append(\"starting saving output files\")\n",
    "\n",
    "# check if directories for output exist. If not, create them\n",
    "storage_locs = validate_output_directories(file_loc)\n",
    "output_path_transcript = storage_locs.get(\"t_out\")\n",
    "output_path_metadata = storage_locs.get(\"m_out\")\n",
    "\n",
    "# label and store this transcription\n",
    "vid_preamble = beautify_filename(filename, num_words=15, start_reverse=False)\n",
    "\n",
    "# transcription\n",
    "transcribed_filename = (\n",
    "    vid_preamble + \"_tscript_\" + datetime.now().strftime(\"_%H.%M.%S\") + \".txt\"\n",
    ")\n",
    "tscript_path = join(output_path_transcript, transcribed_filename)\n",
    "with open(tscript_path, \"w\", encoding=\"utf-8\", errors=\"ignore\") as tfile:\n",
    "    tfile.writelines(full_transcription)\n",
    "# metadata\n",
    "metadata_filename = \"metadata for \" + vid_preamble + \" transcription.txt\"\n",
    "meta_path = join(output_path_metadata, metadata_filename)\n",
    "with open(meta_path, \"w\", encoding=\"utf-8\", errors=\"ignore\") as mfile:\n",
    "    mfile.writelines(metadata)\n",
    "\n",
    "print(\"saved files at the following locations\")\n",
    "print(\"transcript at: \" + output_path_transcript)\n",
    "print(\"metadata at: \" + output_path_metadata)\n",
    "time_log.append(time.perf_counter())\n",
    "time_log_desc.append(\"saved output files to local runtime\")"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "saved files at the following locations\n",
      "transcript at: /content/transcription/wav2vec2_sf_transcript\n",
      "metadata at: /content/transcription/wav2vec2_sf_metadata\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4SRJlg1Zmnd"
   },
   "source": [
    "### Spell Correction\n",
    "\n",
    "**Note that symspell is used here for the spelling + grammar checker instead of Neuspell.** If you wish to use the better version with Neuspell, that is implemented as an example [here](https://colab.research.google.com/drive/1qOUkiPMaUZgBTMfCFF-fCRTPCMg1997J?usp=sharing)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g2TGZ4h041vU",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "outputId": "07e7bc63-df04-4efe-f47d-9c2313291913"
   },
   "source": [
    "# spell correction, sentence disambiguation, and keyword extraction\n",
    "\n",
    "# Go through base transcription files and spell correct them and get keywords\n",
    "print(\"\\n Starting to spell-correct and extract keywords\\n\")\n",
    "seg = pysbd.Segmenter(language=\"en\", clean=True)\n",
    "tf_pretty_name = beautify_filename(\n",
    "    transcribed_filename, start_reverse=False, num_words=10\n",
    ")\n",
    "# auto-correct spelling (wav2vec2 doesn't enforce spelling on its output)\n",
    "corr_results_fl = symspell_file(\n",
    "    filepath=output_path_transcript,\n",
    "    filename=transcribed_filename,\n",
    "    keep_numb_words=True,\n",
    "    create_folder=True,\n",
    "    dist=2,\n",
    ")\n",
    "output_path_impr = corr_results_fl.get(\"output_path\")\n",
    "\n",
    "# Write version of transcription with sentences / boundaries inferred with periods. All text in one line\n",
    "seg_list = seg.segment(corr_results_fl.get(\"corrected_ssp_text\"))\n",
    "seg_text = \". \".join(seg_list)\n",
    "seg_outname = \"SegTEXT \" + tf_pretty_name + \".txt\"\n",
    "seg_text_path = join(output_path_impr, seg_outname)\n",
    "with open(seg_text_path, \"w\", encoding=\"utf-8\", errors=\"ignore\") as file_seg:\n",
    "    file_seg.write(seg_text)\n",
    "\n",
    "# extract keywords from transcription (once spell-corrected)\n",
    "key_phr_fl = quick_keys(\n",
    "    filepath=output_path_impr,\n",
    "    filename=corr_results_fl.get(\"corrected_ssp_fname\"),\n",
    "    num_keywords=50,\n",
    "    max_ngrams=3,\n",
    "    save_db=False,\n",
    ")\n",
    "key_phr_fl.to_excel(\n",
    "    os.path.join(\n",
    "        output_path_transcript, tf_pretty_name + \"YAKE_extracted_keywords.xlsx\"\n",
    "    )\n",
    ")\n",
    "\n",
    "time_log.append(time.perf_counter())\n",
    "time_log_desc.append(\"transcription spell-corrected + keywords extracted\")"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      " Starting to spell-correct and extract keywords\n",
      "\n",
      "\n",
      "PySymSpell - Starting to correct the file:  jfk_rice_moon_speec_tscript__05.18.31.txt\n",
      "Done correcting  jfk_rice_moon_speec_tscript__05.18.31.txt  at time:  05:18:36 \n",
      "\n",
      "top 5 phrases are: \n",
      "\n",
      "['forty thousand miles',\n",
      " 'space promise high',\n",
      " 'hundred feet tall',\n",
      " 'propulsion guidance control',\n",
      " 'guidance control communications']\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xyVrE9jZA2K"
   },
   "source": [
    "## location of \"final\" transcription"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YLO_EvdNZDQj",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "outputId": "82441296-ad0b-4432-c64c-135ed6ce6cc8"
   },
   "source": [
    "increase_font()\n",
    "print(\n",
    "    \"The final transcription outputs (i.e. the best / fully corrected) are here: \\n\",\n",
    "    output_path_impr,\n",
    ")"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/javascript": [
       "\n",
       "  for (rule of document.styleSheets[0].cssRules){\n",
       "    if (rule.selectorText=='body') {\n",
       "      rule.style.fontSize = '24px'\n",
       "      break\n",
       "    }\n",
       "  }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "The final transcription outputs (i.e. the best / fully corrected) are here: \n",
      " /content/transcription/wav2vec2_sf_transcript/auto-corrected\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGWxhA3boZuJ"
   },
   "source": [
    "## Download generated files"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Zwnan6bXodM_",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "outputId": "14d01573-9df3-4cd4-afe6-9fb324b2c736"
   },
   "source": [
    "from google.colab import files\n",
    "\n",
    "if want_to_download_results:\n",
    "    zip_dir = join(os.getcwd(), \"zipped_outputs\")\n",
    "    os.makedirs(zip_dir, exist_ok=True)\n",
    "    output_header = \"vid2cleantxt_output_\" + datetime.now().strftime(\"%d%m%Y\")\n",
    "    shutil.make_archive(join(zip_dir, output_header), \"zip\", file_loc)\n",
    "    files.download(join(zip_dir, output_header + \".zip\"))\n",
    "    print(\"download started - \", datetime.now())\n",
    "else:\n",
    "    print(\"want_to_download_results is set to: \", want_to_download_results)"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/javascript": [
       "download(\"download_a3f4693f-ec66-476e-b86d-f64906d0f9dc\", \"vid2cleantxt_output_17082021.zip\", 13107925)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "download started -  2021-08-17 05:18:38.981721\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9qbVc4PAcFZ"
   },
   "source": [
    "## Log & Exit"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OOoaNN5f5efD",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "outputId": "b136f777-ea60-4d30-a144-db07c024c251"
   },
   "source": [
    "print(\"\\n\\n----------------- Script Complete -----------------\")\n",
    "print(\"time of completion block: \", datetime.now())\n",
    "print(\"Transcription file + more can be found here: \", output_path_transcript)\n",
    "print(\"Metadata for each transcription is located: \", output_path_metadata)\n",
    "time_log.append(time.perf_counter())\n",
    "time_log_desc.append(\"End\")\n",
    "# save runtime database\n",
    "time_records_db = pd.DataFrame(\n",
    "    list(zip(time_log_desc, time_log)), columns=[\"Event\", \"Time (sec)\"]\n",
    ")\n",
    "time_records_db.to_excel(\n",
    "    join(output_path_metadata, tf_pretty_name + \"transcription_time_log.xlsx\")\n",
    ")\n",
    "# total\n",
    "print(\"total runtime was {0:3f}\".format((time_log[-1] - time_log[0]) / 60), \" minutes\")"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------- Script Complete -----------------\n",
      "time of completion block:  2021-08-17 05:18:39.003680\n",
      "Transcription file + more can be found here:  /content/transcription/wav2vec2_sf_transcript\n",
      "Metadata for each transcription is located:  /content/transcription/wav2vec2_sf_metadata\n",
      "total runtime was 2.591219  minutes\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}
